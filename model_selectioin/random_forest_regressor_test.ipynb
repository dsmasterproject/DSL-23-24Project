{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "development = pd.read_csv(\"./../../DSL_Winter_Project_2024/development.csv\")\n",
    "\n",
    "outlier_column_index=[0, 7, 12, 15, 16, 17]\n",
    "columns_to_drop=[]\n",
    "\n",
    "for index in outlier_column_index:\n",
    "    columns_to_drop.append('pmax[%s]' % index)\n",
    "    columns_to_drop.append('negpmax[%s]' % index)\n",
    "    columns_to_drop.append('tmax[%s]' % index)\n",
    "    columns_to_drop.append('area[%s]' % index)\n",
    "    columns_to_drop.append('rms[%s]' % index)\n",
    "\n",
    "evaluation = pd.read_csv(\"./../../DSL_Winter_Project_2024/evaluation.csv\")\n",
    "eva=evaluation.drop(columns=columns_to_drop)\n",
    "eva_df=eva.drop(columns=[\"Id\"])\n",
    "\n",
    "df=development.drop(columns=columns_to_drop)\n",
    "X=df.drop(columns=['x', 'y'])\n",
    "y=df.loc[:,['x', 'y']]\n",
    "\n",
    "rs=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n",
    "\n",
    "output0.csv\n",
    "\n",
    "distance: 4.576920443421794 (5.122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=100,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=None,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "y_rfr=rfr.predict(X_test)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "eva_y=rfr.predict(eva_df)\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output0.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 260, 'min_samples_split': 50, 'min_samples_leaf': 50, 'max_features': 'sqrt', 'max_depth': 100}\n",
    "\n",
    "output1.csv\n",
    "\n",
    "distance: 5.929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.563470114295041\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=260,min_samples_split=50,min_samples_leaf=50,max_features='sqrt',max_depth=100,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "eva_y=rfr.predict(eva_df)\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output1.csv', index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 50}\n",
    "\n",
    "output2.csv\n",
    "\n",
    "distance: 5.031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.494897256772761\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=200,min_samples_split=5,min_samples_leaf=1,max_features='sqrt',max_depth=50,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output2.csv', index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.441804259159674\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=500,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output3.csv', index=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.501637990431042\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=200,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=20,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output4.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 350, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.472743778568188\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=350,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=20,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output5.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 490, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.442287968155777\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=490,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=None,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output6.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4497516078756485\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=490,min_samples_split=5,min_samples_leaf=1,max_features='sqrt',max_depth=50,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output7.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 495, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.460348824798174\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=495,min_samples_split=2,min_samples_leaf=2,max_features='sqrt',max_depth=45,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output8.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'n_estimators': 550, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 150}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.438729011590766\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=550,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output9.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.426690679410952\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=800,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output10.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.420698153416437\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=1200,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=200,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output11.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.412443094058066\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=3000,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=200,random_state=rs)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output12.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 5149.0020 - val_loss: 2198.6707\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 789.8791 - val_loss: 769.4656\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 475us/step - loss: 137.9995 - val_loss: 825.5518\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 80.2341 - val_loss: 934.8686\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 95.9943 - val_loss: 1189.6565\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 69.4150 - val_loss: 1065.1541\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 3s 454us/step - loss: 81.0731 - val_loss: 1135.2229\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 3s 450us/step - loss: 66.1952 - val_loss: 1027.7122\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 60.0229 - val_loss: 926.1052\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 455us/step - loss: 66.3857 - val_loss: 768.6426\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 43.4893 - val_loss: 1019.6464\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 3s 452us/step - loss: 42.6728 - val_loss: 696.1090\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 42.4901 - val_loss: 791.2830\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 35.9863 - val_loss: 687.8557\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 459us/step - loss: 35.5585 - val_loss: 653.8782\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 30.6552 - val_loss: 523.4903\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 32.1942 - val_loss: 615.4139\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 29.5932 - val_loss: 563.9923\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 32.3905 - val_loss: 310.9142\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 462us/step - loss: 26.2670 - val_loss: 248.1516\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 3s 452us/step - loss: 28.4238 - val_loss: 704.7885\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 29.2744 - val_loss: 473.3849\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 27.8980 - val_loss: 531.2765\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 458us/step - loss: 27.0438 - val_loss: 731.5786\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 463us/step - loss: 28.0615 - val_loss: 487.5953\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 458us/step - loss: 26.8529 - val_loss: 512.9246\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 26.6459 - val_loss: 319.9047\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 3s 448us/step - loss: 24.2819 - val_loss: 305.8122\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 26.9507 - val_loss: 670.9254\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 459us/step - loss: 25.8065 - val_loss: 426.2496\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 510us/step - loss: 24.9829 - val_loss: 310.7433\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 23.0163 - val_loss: 641.5978\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 25.1210 - val_loss: 636.9828\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 26.0148 - val_loss: 335.3322\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 27.6922 - val_loss: 574.4395\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 23.9047 - val_loss: 330.1531\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 24.2720 - val_loss: 262.2712\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 24.5411 - val_loss: 388.4242\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 462us/step - loss: 22.1053 - val_loss: 762.4196\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 462us/step - loss: 20.8033 - val_loss: 415.4099\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 460us/step - loss: 24.9759 - val_loss: 267.1811\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 455us/step - loss: 21.9488 - val_loss: 442.6662\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 21.2070 - val_loss: 376.4264\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 454us/step - loss: 22.2530 - val_loss: 611.5332\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 455us/step - loss: 23.6958 - val_loss: 390.5405\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 3s 452us/step - loss: 22.4950 - val_loss: 490.2391\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 456us/step - loss: 22.6665 - val_loss: 432.1601\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 22.3661 - val_loss: 256.3332\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 3s 447us/step - loss: 21.6308 - val_loss: 361.7976\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 3s 453us/step - loss: 23.0559 - val_loss: 569.6152\n",
      "2410/2410 [==============================] - 1s 248us/step\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='relu', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29618979662101\n"
     ]
    }
   ],
   "source": [
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 36121.3906 - val_loss: 3326.0532\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 744.3203 - val_loss: 54.5026\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 477us/step - loss: 34.1684 - val_loss: 35.5989\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 26.8506 - val_loss: 28.7888\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 23.5371 - val_loss: 24.8251\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 21.6698 - val_loss: 23.9111\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 20.2351 - val_loss: 23.5579\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 19.0806 - val_loss: 21.7137\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 18.3771 - val_loss: 21.6108\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 17.6943 - val_loss: 20.7856\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 17.2043 - val_loss: 20.3594\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 16.7668 - val_loss: 20.1893\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 16.4306 - val_loss: 19.6719\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 16.1435 - val_loss: 19.5704\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 502us/step - loss: 15.9044 - val_loss: 20.0044\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 15.6199 - val_loss: 19.1419\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 467us/step - loss: 15.3109 - val_loss: 19.1130\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 461us/step - loss: 15.1006 - val_loss: 18.9274\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.9444 - val_loss: 18.7063\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 14.6566 - val_loss: 18.5925\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 14.5235 - val_loss: 18.5738\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 14.4071 - val_loss: 19.0363\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 497us/step - loss: 14.1321 - val_loss: 17.9570\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 14.0958 - val_loss: 18.3863\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 13.9940 - val_loss: 18.6172\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 501us/step - loss: 13.8916 - val_loss: 18.7223\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 13.7179 - val_loss: 18.0267\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.6841 - val_loss: 18.0281\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.6722 - val_loss: 17.9728\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 13.5642 - val_loss: 19.0802\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 13.4745 - val_loss: 18.0003\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 13.3454 - val_loss: 17.8449\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 13.2748 - val_loss: 17.9827\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 13.2354 - val_loss: 18.1135\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 487us/step - loss: 13.1849 - val_loss: 18.1263\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 13.0857 - val_loss: 17.4032\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 13.0644 - val_loss: 17.4300\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 12.9433 - val_loss: 17.5418\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 12.9335 - val_loss: 18.0020\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.8143 - val_loss: 17.8487\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 12.8829 - val_loss: 18.4897\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 12.6896 - val_loss: 17.9726\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 494us/step - loss: 12.7261 - val_loss: 18.1095\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 463us/step - loss: 12.6822 - val_loss: 18.1289\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 460us/step - loss: 12.5728 - val_loss: 17.6661\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 469us/step - loss: 12.5588 - val_loss: 17.5613\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 12.5741 - val_loss: 17.7652\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 12.4725 - val_loss: 17.7241\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 12.4022 - val_loss: 17.5913\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 468us/step - loss: 12.4088 - val_loss: 17.2829\n",
      "2410/2410 [==============================] - 1s 245us/step\n",
      "4.2332971267991395\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)  # 输出层，2个神经元对应 x 和 y\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 5s 597us/step - loss: 32012.1816 - val_loss: 1559.0292\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 5s 588us/step - loss: 301.3584 - val_loss: 45.8746\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 31.9268 - val_loss: 35.7359\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 5s 600us/step - loss: 26.9055 - val_loss: 32.4825\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 5s 584us/step - loss: 24.3515 - val_loss: 28.7360\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 581us/step - loss: 22.3432 - val_loss: 26.8934\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 5s 604us/step - loss: 20.9128 - val_loss: 25.1679\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 5s 604us/step - loss: 19.5159 - val_loss: 23.3762\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 18.4508 - val_loss: 22.6567\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 5s 634us/step - loss: 17.5072 - val_loss: 22.3284\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 5s 604us/step - loss: 16.8278 - val_loss: 22.3882\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 5s 603us/step - loss: 16.2861 - val_loss: 21.6397\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 555us/step - loss: 15.9802 - val_loss: 21.2393\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 561us/step - loss: 15.5371 - val_loss: 21.5970\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 556us/step - loss: 15.2331 - val_loss: 20.5822\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 5s 609us/step - loss: 15.0173 - val_loss: 21.2279\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 580us/step - loss: 14.9049 - val_loss: 20.4372\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 14.6368 - val_loss: 20.9040\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 14.5037 - val_loss: 20.5850\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 14.2720 - val_loss: 19.8129\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 14.1399 - val_loss: 19.5689\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 575us/step - loss: 14.0093 - val_loss: 19.3093\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 5s 603us/step - loss: 13.8610 - val_loss: 19.3686\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 5s 598us/step - loss: 13.7952 - val_loss: 19.0340\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 5s 603us/step - loss: 13.6503 - val_loss: 18.3937\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 5s 606us/step - loss: 13.5525 - val_loss: 19.8608\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 5s 599us/step - loss: 13.4580 - val_loss: 18.9956\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 5s 600us/step - loss: 13.3799 - val_loss: 19.2197\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 5s 626us/step - loss: 13.2189 - val_loss: 19.0299\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 5s 657us/step - loss: 13.1705 - val_loss: 18.9163\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 5s 615us/step - loss: 13.1302 - val_loss: 18.7231\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 5s 606us/step - loss: 13.0051 - val_loss: 18.8957\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 5s 609us/step - loss: 12.9463 - val_loss: 18.7920\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 537us/step - loss: 12.8583 - val_loss: 19.1303\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 540us/step - loss: 12.8528 - val_loss: 18.9269\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 545us/step - loss: 12.7734 - val_loss: 19.2714\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 582us/step - loss: 12.6607 - val_loss: 17.7927\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 5s 605us/step - loss: 12.6958 - val_loss: 19.0258\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 5s 630us/step - loss: 12.6786 - val_loss: 18.4720\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 5s 644us/step - loss: 12.5460 - val_loss: 19.0758\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 5s 641us/step - loss: 12.4953 - val_loss: 18.3699\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 5s 641us/step - loss: 12.4303 - val_loss: 18.7158\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 5s 617us/step - loss: 12.3415 - val_loss: 18.3576\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 5s 598us/step - loss: 12.3220 - val_loss: 18.0194\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 5s 610us/step - loss: 12.2767 - val_loss: 17.8967\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 5s 628us/step - loss: 12.2108 - val_loss: 17.8521\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 567us/step - loss: 12.2045 - val_loss: 17.2175\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 570us/step - loss: 12.0994 - val_loss: 18.3717\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 567us/step - loss: 12.1005 - val_loss: 17.5351\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 564us/step - loss: 12.0090 - val_loss: 18.2216\n",
      "2410/2410 [==============================] - 1s 275us/step\n",
      "4.2441048964513985\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)  # 输出层，2个神经元对应 x 和 y\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=160, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4016/4016 [==============================] - 1s 280us/step\n"
     ]
    }
   ],
   "source": [
    "eva_df_scaled = scaler.transform(eva_df)\n",
    "\n",
    "eva_y=model.predict(eva_df_scaled)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('tensor_output1.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.437238934523309\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "eva_df_scaled = scaler.transform(eva_df)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=550,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=150,random_state=rs)\n",
    "rfr.fit(X_train_scaled, y_train)\n",
    "y_rfr=rfr.predict(X_test_scaled)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df_scaled)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('output13.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMaxScaler is not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 513us/step - loss: 42320.2539 - mae: 164.0027 - acc: 0.5200 - val_loss: 13718.3223 - val_mae: 100.4028 - val_acc: 0.5218\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 5580.7534 - mae: 52.1360 - acc: 0.8182 - val_loss: 249.4449 - val_mae: 10.1418 - val_acc: 0.9776\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 82.8928 - mae: 6.2532 - acc: 0.9803 - val_loss: 46.0678 - val_mae: 5.1367 - val_acc: 0.9823\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 478us/step - loss: 40.9770 - mae: 4.8438 - acc: 0.9826 - val_loss: 37.5230 - val_mae: 4.6528 - val_acc: 0.9839\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 467us/step - loss: 36.5249 - mae: 4.5997 - acc: 0.9830 - val_loss: 34.8087 - val_mae: 4.4972 - val_acc: 0.9817\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 465us/step - loss: 34.3203 - mae: 4.4742 - acc: 0.9833 - val_loss: 33.3961 - val_mae: 4.4218 - val_acc: 0.9815\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 32.9617 - mae: 4.3893 - acc: 0.9840 - val_loss: 32.5892 - val_mae: 4.3730 - val_acc: 0.9833\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 31.9580 - mae: 4.3241 - acc: 0.9844 - val_loss: 32.5892 - val_mae: 4.3480 - val_acc: 0.9837\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 31.1842 - mae: 4.2766 - acc: 0.9846 - val_loss: 29.8942 - val_mae: 4.1824 - val_acc: 0.9845\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 466us/step - loss: 30.6332 - mae: 4.2403 - acc: 0.9847 - val_loss: 30.2781 - val_mae: 4.2182 - val_acc: 0.9836\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 467us/step - loss: 30.0495 - mae: 4.2014 - acc: 0.9850 - val_loss: 30.8512 - val_mae: 4.2612 - val_acc: 0.9808\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 478us/step - loss: 29.6194 - mae: 4.1724 - acc: 0.9849 - val_loss: 30.1398 - val_mae: 4.2103 - val_acc: 0.9843\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 29.2571 - mae: 4.1486 - acc: 0.9851 - val_loss: 28.4116 - val_mae: 4.0855 - val_acc: 0.9836\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 495us/step - loss: 28.9049 - mae: 4.1247 - acc: 0.9852 - val_loss: 28.5228 - val_mae: 4.0970 - val_acc: 0.9860\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 28.5587 - mae: 4.1010 - acc: 0.9851 - val_loss: 27.8471 - val_mae: 4.0462 - val_acc: 0.9849\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 28.2686 - mae: 4.0788 - acc: 0.9855 - val_loss: 27.4939 - val_mae: 4.0238 - val_acc: 0.9852\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 28.0044 - mae: 4.0604 - acc: 0.9855 - val_loss: 28.1617 - val_mae: 4.0740 - val_acc: 0.9856\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 27.8067 - mae: 4.0467 - acc: 0.9855 - val_loss: 27.3874 - val_mae: 4.0170 - val_acc: 0.9845\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 471us/step - loss: 27.5303 - mae: 4.0278 - acc: 0.9854 - val_loss: 27.0390 - val_mae: 3.9882 - val_acc: 0.9857\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 27.3366 - mae: 4.0147 - acc: 0.9854 - val_loss: 26.7996 - val_mae: 3.9675 - val_acc: 0.9848\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 27.1328 - mae: 3.9977 - acc: 0.9856 - val_loss: 26.7600 - val_mae: 3.9684 - val_acc: 0.9869\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 26.9853 - mae: 3.9894 - acc: 0.9857 - val_loss: 26.6921 - val_mae: 3.9649 - val_acc: 0.9852\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 26.8010 - mae: 3.9718 - acc: 0.9857 - val_loss: 29.4320 - val_mae: 4.1418 - val_acc: 0.9857\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 26.6483 - mae: 3.9627 - acc: 0.9855 - val_loss: 26.2632 - val_mae: 3.9300 - val_acc: 0.9863\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 26.4722 - mae: 3.9495 - acc: 0.9857 - val_loss: 26.5375 - val_mae: 3.9403 - val_acc: 0.9851\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 26.3751 - mae: 3.9418 - acc: 0.9857 - val_loss: 25.9531 - val_mae: 3.9050 - val_acc: 0.9868\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 26.2293 - mae: 3.9321 - acc: 0.9858 - val_loss: 26.4136 - val_mae: 3.9394 - val_acc: 0.9863\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 26.0822 - mae: 3.9207 - acc: 0.9857 - val_loss: 26.9351 - val_mae: 3.9892 - val_acc: 0.9861\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 470us/step - loss: 25.9317 - mae: 3.9101 - acc: 0.9857 - val_loss: 25.5131 - val_mae: 3.8745 - val_acc: 0.9862\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 25.8380 - mae: 3.9025 - acc: 0.9857 - val_loss: 25.5259 - val_mae: 3.8736 - val_acc: 0.9864\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 473us/step - loss: 25.6875 - mae: 3.8909 - acc: 0.9859 - val_loss: 24.9810 - val_mae: 3.8306 - val_acc: 0.9861\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 25.6111 - mae: 3.8853 - acc: 0.9857 - val_loss: 25.1219 - val_mae: 3.8424 - val_acc: 0.9865\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 496us/step - loss: 25.4894 - mae: 3.8767 - acc: 0.9860 - val_loss: 25.6733 - val_mae: 3.8872 - val_acc: 0.9864\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 25.3904 - mae: 3.8679 - acc: 0.9860 - val_loss: 26.0258 - val_mae: 3.9256 - val_acc: 0.9854\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 25.2891 - mae: 3.8609 - acc: 0.9858 - val_loss: 25.1487 - val_mae: 3.8392 - val_acc: 0.9847\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 25.1425 - mae: 3.8512 - acc: 0.9860 - val_loss: 25.4672 - val_mae: 3.8734 - val_acc: 0.9847\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 25.0727 - mae: 3.8454 - acc: 0.9859 - val_loss: 27.1215 - val_mae: 4.0083 - val_acc: 0.9827\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.9540 - mae: 3.8348 - acc: 0.9860 - val_loss: 25.2948 - val_mae: 3.8510 - val_acc: 0.9854\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.8797 - mae: 3.8305 - acc: 0.9859 - val_loss: 25.3400 - val_mae: 3.8661 - val_acc: 0.9872\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.7564 - mae: 3.8217 - acc: 0.9860 - val_loss: 24.6163 - val_mae: 3.8025 - val_acc: 0.9864\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 24.6619 - mae: 3.8144 - acc: 0.9861 - val_loss: 24.7914 - val_mae: 3.8198 - val_acc: 0.9862\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 24.5901 - mae: 3.8081 - acc: 0.9860 - val_loss: 24.3014 - val_mae: 3.7803 - val_acc: 0.9862\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 24.5105 - mae: 3.8012 - acc: 0.9860 - val_loss: 24.4802 - val_mae: 3.7976 - val_acc: 0.9869\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 24.4210 - mae: 3.7956 - acc: 0.9860 - val_loss: 24.9706 - val_mae: 3.8405 - val_acc: 0.9849\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 490us/step - loss: 24.3434 - mae: 3.7905 - acc: 0.9860 - val_loss: 25.1940 - val_mae: 3.8622 - val_acc: 0.9839\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 490us/step - loss: 24.2537 - mae: 3.7833 - acc: 0.9861 - val_loss: 24.2957 - val_mae: 3.7827 - val_acc: 0.9856\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 24.1840 - mae: 3.7757 - acc: 0.9862 - val_loss: 24.6142 - val_mae: 3.8112 - val_acc: 0.9851\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 24.1022 - mae: 3.7724 - acc: 0.9862 - val_loss: 24.3055 - val_mae: 3.7809 - val_acc: 0.9868\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 24.0615 - mae: 3.7681 - acc: 0.9861 - val_loss: 24.2554 - val_mae: 3.7843 - val_acc: 0.9870\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.0201 - mae: 3.7661 - acc: 0.9861 - val_loss: 23.7557 - val_mae: 3.7394 - val_acc: 0.9862\n",
      "2410/2410 [==============================] - 1s 242us/step\n",
      "5.890410082861226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 494us/step - loss: 37744.1055 - r2_score: -1.7611 - val_loss: 3140.5564 - val_r2_score: 0.7702\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 711.0061 - r2_score: 0.9479 - val_loss: 57.1373 - val_r2_score: 0.9958\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 34.6180 - r2_score: 0.9975 - val_loss: 37.2465 - val_r2_score: 0.9973\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 27.4841 - r2_score: 0.9980 - val_loss: 32.9347 - val_r2_score: 0.9976\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 24.7020 - r2_score: 0.9982 - val_loss: 29.4982 - val_r2_score: 0.9978\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 22.2817 - r2_score: 0.9984 - val_loss: 29.4373 - val_r2_score: 0.9979\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 20.5097 - r2_score: 0.9985 - val_loss: 25.6101 - val_r2_score: 0.9981\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 19.4120 - r2_score: 0.9986 - val_loss: 23.6673 - val_r2_score: 0.9983\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 495us/step - loss: 18.5439 - r2_score: 0.9986 - val_loss: 21.8033 - val_r2_score: 0.9984\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 490us/step - loss: 17.7128 - r2_score: 0.9987 - val_loss: 20.9082 - val_r2_score: 0.9985\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 499us/step - loss: 17.2824 - r2_score: 0.9987 - val_loss: 20.4488 - val_r2_score: 0.9985\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 495us/step - loss: 16.6483 - r2_score: 0.9988 - val_loss: 20.5254 - val_r2_score: 0.9985\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 16.3166 - r2_score: 0.9988 - val_loss: 20.2477 - val_r2_score: 0.9985\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 15.9331 - r2_score: 0.9988 - val_loss: 20.0698 - val_r2_score: 0.9985\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 15.6641 - r2_score: 0.9988 - val_loss: 20.2350 - val_r2_score: 0.9985\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 15.4677 - r2_score: 0.9989 - val_loss: 19.9070 - val_r2_score: 0.9985\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 15.1996 - r2_score: 0.9989 - val_loss: 19.6847 - val_r2_score: 0.9986\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 495us/step - loss: 15.1751 - r2_score: 0.9989 - val_loss: 19.5440 - val_r2_score: 0.9986\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 14.8303 - r2_score: 0.9989 - val_loss: 19.1236 - val_r2_score: 0.9986\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 14.6960 - r2_score: 0.9989 - val_loss: 19.9180 - val_r2_score: 0.9985\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 496us/step - loss: 14.5503 - r2_score: 0.9989 - val_loss: 19.4713 - val_r2_score: 0.9986\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 505us/step - loss: 14.4468 - r2_score: 0.9989 - val_loss: 18.6594 - val_r2_score: 0.9986\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 14.2812 - r2_score: 0.9989 - val_loss: 18.6639 - val_r2_score: 0.9986\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 14.1374 - r2_score: 0.9990 - val_loss: 18.4896 - val_r2_score: 0.9986\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 14.0447 - r2_score: 0.9990 - val_loss: 18.4787 - val_r2_score: 0.9986\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 13.8685 - r2_score: 0.9990 - val_loss: 18.5059 - val_r2_score: 0.9986\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 494us/step - loss: 13.7895 - r2_score: 0.9990 - val_loss: 18.2905 - val_r2_score: 0.9987\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 490us/step - loss: 13.6113 - r2_score: 0.9990 - val_loss: 18.1669 - val_r2_score: 0.9987\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 498us/step - loss: 13.5838 - r2_score: 0.9990 - val_loss: 18.9420 - val_r2_score: 0.9986\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 13.4644 - r2_score: 0.9990 - val_loss: 17.8348 - val_r2_score: 0.9987\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 13.3689 - r2_score: 0.9990 - val_loss: 18.1118 - val_r2_score: 0.9987\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 13.3462 - r2_score: 0.9990 - val_loss: 17.9225 - val_r2_score: 0.9987\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 13.3214 - r2_score: 0.9990 - val_loss: 18.2226 - val_r2_score: 0.9987\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 13.2475 - r2_score: 0.9990 - val_loss: 17.5496 - val_r2_score: 0.9987\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 13.2408 - r2_score: 0.9990 - val_loss: 18.2595 - val_r2_score: 0.9987\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 13.1032 - r2_score: 0.9990 - val_loss: 17.7224 - val_r2_score: 0.9987\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 13.1197 - r2_score: 0.9990 - val_loss: 18.1921 - val_r2_score: 0.9987\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 12.9292 - r2_score: 0.9990 - val_loss: 18.1263 - val_r2_score: 0.9987\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 13.0050 - r2_score: 0.9990 - val_loss: 18.0148 - val_r2_score: 0.9987\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 490us/step - loss: 12.8760 - r2_score: 0.9990 - val_loss: 18.4805 - val_r2_score: 0.9986\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.7956 - r2_score: 0.9991 - val_loss: 18.1546 - val_r2_score: 0.9987\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 487us/step - loss: 12.7386 - r2_score: 0.9991 - val_loss: 18.0702 - val_r2_score: 0.9987\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 496us/step - loss: 12.6782 - r2_score: 0.9991 - val_loss: 18.4671 - val_r2_score: 0.9986\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 12.5983 - r2_score: 0.9991 - val_loss: 18.0913 - val_r2_score: 0.9987\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 492us/step - loss: 12.6627 - r2_score: 0.9991 - val_loss: 17.8299 - val_r2_score: 0.9987\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 12.5357 - r2_score: 0.9991 - val_loss: 18.3306 - val_r2_score: 0.9987\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 493us/step - loss: 12.5300 - r2_score: 0.9991 - val_loss: 18.3077 - val_r2_score: 0.9987\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.4621 - r2_score: 0.9991 - val_loss: 17.8760 - val_r2_score: 0.9987\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 12.4747 - r2_score: 0.9991 - val_loss: 18.2154 - val_r2_score: 0.9987\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 12.4680 - r2_score: 0.9991 - val_loss: 18.0747 - val_r2_score: 0.9987\n",
      "2410/2410 [==============================] - 1s 248us/step\n",
      "4.183264031887704\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=keras.metrics.R2Score())\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmax and area are two features with linear correlation, but removing them here does not improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmax_features = []\n",
    "area_features = []\n",
    "\n",
    "for i in range(0, 18):\n",
    "    if(i in outlier_column_index):\n",
    "        continue\n",
    "    pmax_features.append(\"pmax[%s]\" % (i))\n",
    "    area_features.append(\"area[%s]\" % (i))\n",
    "\n",
    "X_train_drop_pmax = X_train.drop(columns=pmax_features + area_features)\n",
    "X_test_drop_pmax=X_test.drop(columns=pmax_features + area_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 5s 618us/step - loss: 37451.3320 - mae: 145.4534 - acc: 0.6329 - val_loss: 3946.4587 - val_mae: 48.1615 - val_acc: 0.9624\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 5s 588us/step - loss: 982.5688 - mae: 18.7409 - acc: 0.9713 - val_loss: 134.8243 - val_mae: 7.5034 - val_acc: 0.9760\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 5s 599us/step - loss: 109.7859 - mae: 6.6884 - acc: 0.9757 - val_loss: 100.2411 - val_mae: 6.3630 - val_acc: 0.9771\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 5s 592us/step - loss: 93.9059 - mae: 6.1261 - acc: 0.9765 - val_loss: 89.4347 - val_mae: 5.9818 - val_acc: 0.9784\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 5s 618us/step - loss: 86.8402 - mae: 5.8874 - acc: 0.9776 - val_loss: 82.6455 - val_mae: 5.7326 - val_acc: 0.9791\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 5s 599us/step - loss: 82.1001 - mae: 5.7223 - acc: 0.9783 - val_loss: 79.5731 - val_mae: 5.6445 - val_acc: 0.9797\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 5s 595us/step - loss: 78.4995 - mae: 5.6030 - acc: 0.9790 - val_loss: 82.6572 - val_mae: 5.8450 - val_acc: 0.9795\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 582us/step - loss: 75.7488 - mae: 5.5073 - acc: 0.9790 - val_loss: 74.1654 - val_mae: 5.4561 - val_acc: 0.9787\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 5s 593us/step - loss: 73.6616 - mae: 5.4331 - acc: 0.9796 - val_loss: 72.5866 - val_mae: 5.3816 - val_acc: 0.9805\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 71.3375 - mae: 5.3651 - acc: 0.9798 - val_loss: 72.2979 - val_mae: 5.4003 - val_acc: 0.9805\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 5s 594us/step - loss: 69.7330 - mae: 5.3137 - acc: 0.9799 - val_loss: 70.6872 - val_mae: 5.2924 - val_acc: 0.9814\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 5s 598us/step - loss: 68.1750 - mae: 5.2698 - acc: 0.9802 - val_loss: 68.6884 - val_mae: 5.2239 - val_acc: 0.9805\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 571us/step - loss: 66.5559 - mae: 5.2239 - acc: 0.9804 - val_loss: 67.8776 - val_mae: 5.2133 - val_acc: 0.9813\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 577us/step - loss: 65.3331 - mae: 5.1835 - acc: 0.9806 - val_loss: 66.8167 - val_mae: 5.1858 - val_acc: 0.9803\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 573us/step - loss: 64.0550 - mae: 5.1519 - acc: 0.9806 - val_loss: 67.4862 - val_mae: 5.2374 - val_acc: 0.9815\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 575us/step - loss: 63.1833 - mae: 5.1183 - acc: 0.9806 - val_loss: 65.3473 - val_mae: 5.1348 - val_acc: 0.9797\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 582us/step - loss: 62.0845 - mae: 5.0853 - acc: 0.9806 - val_loss: 66.0108 - val_mae: 5.1874 - val_acc: 0.9810\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 5s 592us/step - loss: 61.3779 - mae: 5.0593 - acc: 0.9808 - val_loss: 64.3023 - val_mae: 5.0822 - val_acc: 0.9805\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 5s 601us/step - loss: 60.5679 - mae: 5.0368 - acc: 0.9811 - val_loss: 63.4414 - val_mae: 5.0631 - val_acc: 0.9814\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 5s 600us/step - loss: 59.7034 - mae: 5.0044 - acc: 0.9811 - val_loss: 62.5945 - val_mae: 5.0272 - val_acc: 0.9810\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 5s 594us/step - loss: 59.0291 - mae: 4.9822 - acc: 0.9813 - val_loss: 62.1418 - val_mae: 5.0157 - val_acc: 0.9808\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 5s 590us/step - loss: 58.0533 - mae: 4.9589 - acc: 0.9812 - val_loss: 62.0078 - val_mae: 5.0174 - val_acc: 0.9817\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 57.4474 - mae: 4.9447 - acc: 0.9816 - val_loss: 61.4870 - val_mae: 5.0102 - val_acc: 0.9810\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 554us/step - loss: 56.6592 - mae: 4.9228 - acc: 0.9816 - val_loss: 60.8418 - val_mae: 4.9744 - val_acc: 0.9817\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 542us/step - loss: 55.9896 - mae: 4.9032 - acc: 0.9817 - val_loss: 59.8794 - val_mae: 4.9593 - val_acc: 0.9822\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 564us/step - loss: 55.1626 - mae: 4.8863 - acc: 0.9817 - val_loss: 59.2655 - val_mae: 4.9041 - val_acc: 0.9822\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 555us/step - loss: 54.4994 - mae: 4.8702 - acc: 0.9816 - val_loss: 59.4096 - val_mae: 4.9432 - val_acc: 0.9817\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 538us/step - loss: 53.8632 - mae: 4.8561 - acc: 0.9820 - val_loss: 59.1065 - val_mae: 4.9195 - val_acc: 0.9816\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 524us/step - loss: 53.2934 - mae: 4.8378 - acc: 0.9820 - val_loss: 58.0731 - val_mae: 4.8829 - val_acc: 0.9824\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 534us/step - loss: 52.8072 - mae: 4.8238 - acc: 0.9819 - val_loss: 57.4550 - val_mae: 4.8537 - val_acc: 0.9829\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 536us/step - loss: 52.3160 - mae: 4.8100 - acc: 0.9822 - val_loss: 58.1926 - val_mae: 4.9128 - val_acc: 0.9812\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 535us/step - loss: 51.7713 - mae: 4.7965 - acc: 0.9823 - val_loss: 58.0547 - val_mae: 4.9160 - val_acc: 0.9817\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 560us/step - loss: 51.5679 - mae: 4.7838 - acc: 0.9822 - val_loss: 56.7542 - val_mae: 4.8398 - val_acc: 0.9826\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 568us/step - loss: 51.0193 - mae: 4.7709 - acc: 0.9823 - val_loss: 56.4175 - val_mae: 4.8152 - val_acc: 0.9825\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 560us/step - loss: 50.7590 - mae: 4.7597 - acc: 0.9824 - val_loss: 56.2639 - val_mae: 4.8118 - val_acc: 0.9827\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 543us/step - loss: 50.7028 - mae: 4.7481 - acc: 0.9823 - val_loss: 56.1487 - val_mae: 4.7920 - val_acc: 0.9822\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 553us/step - loss: 50.1438 - mae: 4.7341 - acc: 0.9824 - val_loss: 57.1377 - val_mae: 4.8672 - val_acc: 0.9827\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 49.7803 - mae: 4.7292 - acc: 0.9823 - val_loss: 55.4635 - val_mae: 4.7619 - val_acc: 0.9825\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 549us/step - loss: 49.4926 - mae: 4.7194 - acc: 0.9822 - val_loss: 55.4772 - val_mae: 4.7702 - val_acc: 0.9827\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 554us/step - loss: 49.2304 - mae: 4.7117 - acc: 0.9824 - val_loss: 55.3849 - val_mae: 4.7883 - val_acc: 0.9821\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 549us/step - loss: 48.8288 - mae: 4.6973 - acc: 0.9823 - val_loss: 57.2063 - val_mae: 4.9206 - val_acc: 0.9830\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 553us/step - loss: 48.6576 - mae: 4.6897 - acc: 0.9825 - val_loss: 54.7840 - val_mae: 4.7783 - val_acc: 0.9826\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 550us/step - loss: 48.2357 - mae: 4.6818 - acc: 0.9825 - val_loss: 55.0686 - val_mae: 4.8069 - val_acc: 0.9831\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 47.9963 - mae: 4.6735 - acc: 0.9824 - val_loss: 53.6677 - val_mae: 4.7173 - val_acc: 0.9829\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 578us/step - loss: 47.8517 - mae: 4.6619 - acc: 0.9827 - val_loss: 53.6511 - val_mae: 4.7328 - val_acc: 0.9826\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 5s 588us/step - loss: 47.5228 - mae: 4.6576 - acc: 0.9827 - val_loss: 53.3111 - val_mae: 4.7229 - val_acc: 0.9832\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 577us/step - loss: 47.2418 - mae: 4.6497 - acc: 0.9826 - val_loss: 53.9495 - val_mae: 4.7352 - val_acc: 0.9822\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 583us/step - loss: 47.1722 - mae: 4.6398 - acc: 0.9826 - val_loss: 54.0480 - val_mae: 4.7698 - val_acc: 0.9831\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 5s 586us/step - loss: 46.7477 - mae: 4.6345 - acc: 0.9826 - val_loss: 53.9695 - val_mae: 4.7459 - val_acc: 0.9830\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 5s 587us/step - loss: 46.5069 - mae: 4.6249 - acc: 0.9827 - val_loss: 52.6389 - val_mae: 4.7088 - val_acc: 0.9832\n",
      "2410/2410 [==============================] - 1s 289us/step\n",
      "7.347435658739749\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_drop_pmax)\n",
    "X_test_scaled = scaler.transform(X_test_drop_pmax)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train_drop_pmax.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9638/9638 [==============================] - 5s 491us/step - loss: 25774.0000 - r2_score: -1.3617 - val_loss: 7004.1685 - val_r2_score: -13.7115\n",
      "Epoch 2/50\n",
      "9638/9638 [==============================] - 5s 482us/step - loss: 113.8280 - r2_score: 0.9892 - val_loss: 873.8254 - val_r2_score: -0.9378\n",
      "Epoch 3/50\n",
      "9638/9638 [==============================] - 5s 484us/step - loss: 26.6330 - r2_score: 0.9976 - val_loss: 742.9373 - val_r2_score: -0.6883\n",
      "Epoch 4/50\n",
      "9638/9638 [==============================] - 5s 472us/step - loss: 23.0726 - r2_score: 0.9979 - val_loss: 742.7293 - val_r2_score: -0.6926\n",
      "Epoch 5/50\n",
      "9638/9638 [==============================] - 5s 472us/step - loss: 20.8735 - r2_score: 0.9981 - val_loss: 768.6355 - val_r2_score: -0.7646\n",
      "Epoch 6/50\n",
      "9638/9638 [==============================] - 5s 475us/step - loss: 19.4799 - r2_score: 0.9982 - val_loss: 763.3143 - val_r2_score: -0.7412\n",
      "Epoch 7/50\n",
      "9638/9638 [==============================] - 5s 482us/step - loss: 18.6061 - r2_score: 0.9983 - val_loss: 755.4217 - val_r2_score: -0.7737\n",
      "Epoch 8/50\n",
      "9638/9638 [==============================] - 5s 488us/step - loss: 17.6708 - r2_score: 0.9984 - val_loss: 800.1814 - val_r2_score: -0.8826\n",
      "Epoch 9/50\n",
      "9638/9638 [==============================] - 5s 477us/step - loss: 17.0456 - r2_score: 0.9984 - val_loss: 791.1411 - val_r2_score: -0.8272\n",
      "Epoch 10/50\n",
      "9638/9638 [==============================] - 5s 480us/step - loss: 16.5265 - r2_score: 0.9985 - val_loss: 811.6251 - val_r2_score: -0.8974\n",
      "Epoch 11/50\n",
      "9638/9638 [==============================] - 5s 478us/step - loss: 15.9251 - r2_score: 0.9985 - val_loss: 803.8556 - val_r2_score: -0.8796\n",
      "Epoch 12/50\n",
      "9638/9638 [==============================] - 5s 480us/step - loss: 15.5077 - r2_score: 0.9986 - val_loss: 814.4917 - val_r2_score: -0.8989\n",
      "Epoch 13/50\n",
      "9638/9638 [==============================] - 5s 481us/step - loss: 15.2733 - r2_score: 0.9986 - val_loss: 782.8817 - val_r2_score: -0.8447\n",
      "Epoch 14/50\n",
      "9638/9638 [==============================] - 5s 479us/step - loss: 15.0236 - r2_score: 0.9986 - val_loss: 815.4858 - val_r2_score: -0.9048\n",
      "Epoch 15/50\n",
      "9638/9638 [==============================] - 5s 479us/step - loss: 14.7866 - r2_score: 0.9986 - val_loss: 840.7312 - val_r2_score: -0.9798\n",
      "Epoch 16/50\n",
      "9638/9638 [==============================] - 5s 482us/step - loss: 14.6102 - r2_score: 0.9987 - val_loss: 837.1029 - val_r2_score: -0.9546\n",
      "Epoch 17/50\n",
      "9638/9638 [==============================] - 5s 480us/step - loss: 14.3495 - r2_score: 0.9987 - val_loss: 841.9582 - val_r2_score: -0.9934\n",
      "Epoch 18/50\n",
      "9638/9638 [==============================] - 5s 477us/step - loss: 14.2327 - r2_score: 0.9987 - val_loss: 827.3825 - val_r2_score: -0.9456\n",
      "Epoch 19/50\n",
      "9638/9638 [==============================] - 5s 469us/step - loss: 14.0409 - r2_score: 0.9987 - val_loss: 836.3633 - val_r2_score: -0.9681\n",
      "Epoch 20/50\n",
      "9638/9638 [==============================] - 5s 468us/step - loss: 13.8516 - r2_score: 0.9987 - val_loss: 845.7023 - val_r2_score: -0.9829\n",
      "Epoch 21/50\n",
      "9638/9638 [==============================] - 5s 469us/step - loss: 13.8025 - r2_score: 0.9987 - val_loss: 850.6176 - val_r2_score: -1.0008\n",
      "Epoch 22/50\n",
      "9638/9638 [==============================] - 5s 470us/step - loss: 13.6480 - r2_score: 0.9987 - val_loss: 812.2636 - val_r2_score: -0.9161\n",
      "Epoch 23/50\n",
      "9638/9638 [==============================] - 5s 476us/step - loss: 13.6124 - r2_score: 0.9988 - val_loss: 811.3174 - val_r2_score: -0.9086\n",
      "Epoch 24/50\n",
      "9638/9638 [==============================] - 5s 482us/step - loss: 13.5516 - r2_score: 0.9988 - val_loss: 826.6958 - val_r2_score: -0.9457\n",
      "Epoch 25/50\n",
      "9638/9638 [==============================] - 5s 491us/step - loss: 13.4152 - r2_score: 0.9988 - val_loss: 839.3491 - val_r2_score: -0.9896\n",
      "Epoch 26/50\n",
      "9638/9638 [==============================] - 5s 479us/step - loss: 13.2402 - r2_score: 0.9988 - val_loss: 844.2333 - val_r2_score: -0.9896\n",
      "Epoch 27/50\n",
      "9638/9638 [==============================] - 5s 482us/step - loss: 13.1902 - r2_score: 0.9988 - val_loss: 864.1857 - val_r2_score: -1.0350\n",
      "Epoch 28/50\n",
      "9638/9638 [==============================] - 5s 479us/step - loss: 13.1638 - r2_score: 0.9988 - val_loss: 844.2757 - val_r2_score: -0.9922\n",
      "Epoch 29/50\n",
      "9638/9638 [==============================] - 5s 489us/step - loss: 13.0202 - r2_score: 0.9988 - val_loss: 853.3550 - val_r2_score: -1.0208\n",
      "Epoch 30/50\n",
      "9638/9638 [==============================] - 5s 471us/step - loss: 12.9094 - r2_score: 0.9988 - val_loss: 847.2609 - val_r2_score: -1.0100\n",
      "Epoch 31/50\n",
      "9638/9638 [==============================] - 5s 479us/step - loss: 12.9343 - r2_score: 0.9988 - val_loss: 833.6733 - val_r2_score: -0.9873\n",
      "Epoch 32/50\n",
      "9638/9638 [==============================] - 5s 474us/step - loss: 12.8528 - r2_score: 0.9988 - val_loss: 835.9417 - val_r2_score: -0.9851\n",
      "Epoch 33/50\n",
      "9638/9638 [==============================] - 5s 474us/step - loss: 12.7339 - r2_score: 0.9988 - val_loss: 847.9317 - val_r2_score: -1.0102\n",
      "Epoch 34/50\n",
      "9638/9638 [==============================] - 5s 471us/step - loss: 12.7027 - r2_score: 0.9988 - val_loss: 852.2026 - val_r2_score: -1.0179\n",
      "Epoch 35/50\n",
      "9638/9638 [==============================] - 5s 473us/step - loss: 12.5783 - r2_score: 0.9988 - val_loss: 839.3180 - val_r2_score: -1.0162\n",
      "Epoch 36/50\n",
      "9638/9638 [==============================] - 5s 472us/step - loss: 12.5989 - r2_score: 0.9988 - val_loss: 848.1299 - val_r2_score: -1.0250\n",
      "Epoch 37/50\n",
      "9638/9638 [==============================] - 5s 472us/step - loss: 12.4930 - r2_score: 0.9989 - val_loss: 853.0909 - val_r2_score: -1.0265\n",
      "Epoch 38/50\n",
      "9638/9638 [==============================] - 5s 474us/step - loss: 12.4579 - r2_score: 0.9989 - val_loss: 855.7281 - val_r2_score: -1.0274\n",
      "Epoch 39/50\n",
      "9638/9638 [==============================] - 5s 471us/step - loss: 12.4957 - r2_score: 0.9989 - val_loss: 843.9296 - val_r2_score: -1.0022\n",
      "Epoch 40/50\n",
      "9638/9638 [==============================] - 5s 483us/step - loss: 12.3556 - r2_score: 0.9989 - val_loss: 837.5009 - val_r2_score: -0.9873\n",
      "Epoch 41/50\n",
      "9638/9638 [==============================] - 5s 492us/step - loss: 12.3582 - r2_score: 0.9989 - val_loss: 846.8694 - val_r2_score: -1.0155\n",
      "Epoch 42/50\n",
      "9638/9638 [==============================] - 5s 484us/step - loss: 12.3272 - r2_score: 0.9989 - val_loss: 826.9639 - val_r2_score: -0.9798\n",
      "Epoch 43/50\n",
      "9638/9638 [==============================] - 5s 487us/step - loss: 12.2196 - r2_score: 0.9989 - val_loss: 855.3799 - val_r2_score: -1.0339\n",
      "Epoch 44/50\n",
      "9638/9638 [==============================] - 5s 485us/step - loss: 12.2108 - r2_score: 0.9989 - val_loss: 842.4056 - val_r2_score: -1.0068\n",
      "Epoch 45/50\n",
      "9638/9638 [==============================] - 5s 486us/step - loss: 12.1580 - r2_score: 0.9989 - val_loss: 828.6872 - val_r2_score: -0.9764\n",
      "Epoch 46/50\n",
      "9638/9638 [==============================] - 5s 484us/step - loss: 12.1729 - r2_score: 0.9989 - val_loss: 799.3561 - val_r2_score: -0.9026\n",
      "Epoch 47/50\n",
      "9638/9638 [==============================] - 5s 487us/step - loss: 12.1214 - r2_score: 0.9989 - val_loss: 864.0073 - val_r2_score: -1.0538\n",
      "Epoch 48/50\n",
      "9638/9638 [==============================] - 5s 485us/step - loss: 12.0473 - r2_score: 0.9989 - val_loss: 820.9916 - val_r2_score: -0.9661\n",
      "Epoch 49/50\n",
      "9638/9638 [==============================] - 5s 488us/step - loss: 12.0037 - r2_score: 0.9989 - val_loss: 845.6183 - val_r2_score: -1.0087\n",
      "Epoch 50/50\n",
      "9638/9638 [==============================] - 5s 486us/step - loss: 12.0106 - r2_score: 0.9989 - val_loss: 820.6496 - val_r2_score: -0.9502\n",
      "2410/2410 [==============================] - 1s 251us/step\n",
      "10.239239907032333\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=keras.metrics.R2Score())\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 4s 486us/step - loss: 37088.0391 - mae: 142.1130 - acc: 0.7030 - val_loss: 3288.1367 - val_mae: 41.5667 - val_acc: 0.9828\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 4s 475us/step - loss: 741.9468 - mae: 14.2262 - acc: 0.9852 - val_loss: 54.2350 - val_mae: 4.4019 - val_acc: 0.9857\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 35.1575 - mae: 3.8195 - acc: 0.9865 - val_loss: 34.2366 - val_mae: 3.5775 - val_acc: 0.9871\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 27.6627 - mae: 3.4782 - acc: 0.9872 - val_loss: 30.8823 - val_mae: 3.4333 - val_acc: 0.9877\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 24.5981 - mae: 3.3252 - acc: 0.9875 - val_loss: 27.7566 - val_mae: 3.3112 - val_acc: 0.9873\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 22.3377 - mae: 3.2229 - acc: 0.9879 - val_loss: 27.2487 - val_mae: 3.3519 - val_acc: 0.9890\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 4s 497us/step - loss: 20.5367 - mae: 3.1419 - acc: 0.9880 - val_loss: 25.4783 - val_mae: 3.2511 - val_acc: 0.9881\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 19.3747 - mae: 3.0830 - acc: 0.9881 - val_loss: 23.0237 - val_mae: 3.0715 - val_acc: 0.9885\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 4s 503us/step - loss: 18.3526 - mae: 3.0334 - acc: 0.9884 - val_loss: 22.0327 - val_mae: 3.0289 - val_acc: 0.9892\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 4s 491us/step - loss: 17.5858 - mae: 2.9897 - acc: 0.9885 - val_loss: 21.3666 - val_mae: 3.0169 - val_acc: 0.9895\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 4s 487us/step - loss: 17.2221 - mae: 2.9574 - acc: 0.9887 - val_loss: 20.8772 - val_mae: 2.9689 - val_acc: 0.9887\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 16.6903 - mae: 2.9311 - acc: 0.9887 - val_loss: 21.0766 - val_mae: 2.9933 - val_acc: 0.9897\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 4s 479us/step - loss: 16.3465 - mae: 2.9083 - acc: 0.9888 - val_loss: 20.3555 - val_mae: 2.9351 - val_acc: 0.9895\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 16.1035 - mae: 2.8883 - acc: 0.9887 - val_loss: 20.1695 - val_mae: 2.9354 - val_acc: 0.9898\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 15.8785 - mae: 2.8729 - acc: 0.9886 - val_loss: 22.2945 - val_mae: 3.1935 - val_acc: 0.9858\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 15.5324 - mae: 2.8534 - acc: 0.9891 - val_loss: 19.2100 - val_mae: 2.8922 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 15.4174 - mae: 2.8400 - acc: 0.9889 - val_loss: 19.1096 - val_mae: 2.8684 - val_acc: 0.9901\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 15.2791 - mae: 2.8290 - acc: 0.9890 - val_loss: 19.4984 - val_mae: 2.8804 - val_acc: 0.9905\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 14.9445 - mae: 2.8160 - acc: 0.9890 - val_loss: 18.7879 - val_mae: 2.8185 - val_acc: 0.9898\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 14.8153 - mae: 2.8011 - acc: 0.9890 - val_loss: 18.9656 - val_mae: 2.8372 - val_acc: 0.9889\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 14.6513 - mae: 2.7945 - acc: 0.9890 - val_loss: 18.8737 - val_mae: 2.8291 - val_acc: 0.9894\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 14.5086 - mae: 2.7807 - acc: 0.9891 - val_loss: 18.3251 - val_mae: 2.8131 - val_acc: 0.9890\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 14.3513 - mae: 2.7720 - acc: 0.9891 - val_loss: 19.4163 - val_mae: 2.8724 - val_acc: 0.9889\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 4s 484us/step - loss: 14.2493 - mae: 2.7633 - acc: 0.9892 - val_loss: 18.0810 - val_mae: 2.7911 - val_acc: 0.9905\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 14.1437 - mae: 2.7553 - acc: 0.9890 - val_loss: 18.2254 - val_mae: 2.7740 - val_acc: 0.9899\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 14.0743 - mae: 2.7466 - acc: 0.9893 - val_loss: 17.8934 - val_mae: 2.7768 - val_acc: 0.9899\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 13.8569 - mae: 2.7380 - acc: 0.9891 - val_loss: 17.7318 - val_mae: 2.7867 - val_acc: 0.9894\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 13.7794 - mae: 2.7308 - acc: 0.9893 - val_loss: 18.8765 - val_mae: 2.8256 - val_acc: 0.9891\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 13.7204 - mae: 2.7254 - acc: 0.9891 - val_loss: 19.4394 - val_mae: 2.8038 - val_acc: 0.9900\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 4s 500us/step - loss: 13.5971 - mae: 2.7179 - acc: 0.9892 - val_loss: 18.5505 - val_mae: 2.7694 - val_acc: 0.9896\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 4s 482us/step - loss: 13.5975 - mae: 2.7141 - acc: 0.9891 - val_loss: 18.9095 - val_mae: 2.7712 - val_acc: 0.9904\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 4s 502us/step - loss: 13.4507 - mae: 2.7049 - acc: 0.9892 - val_loss: 19.3063 - val_mae: 2.7812 - val_acc: 0.9893\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 13.4257 - mae: 2.7000 - acc: 0.9895 - val_loss: 18.4061 - val_mae: 2.7608 - val_acc: 0.9887\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 4s 487us/step - loss: 13.3723 - mae: 2.6947 - acc: 0.9892 - val_loss: 18.6423 - val_mae: 2.7503 - val_acc: 0.9893\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 13.3915 - mae: 2.6890 - acc: 0.9894 - val_loss: 19.0896 - val_mae: 2.8131 - val_acc: 0.9889\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 13.1978 - mae: 2.6834 - acc: 0.9894 - val_loss: 18.4419 - val_mae: 2.7186 - val_acc: 0.9887\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 13.1747 - mae: 2.6801 - acc: 0.9894 - val_loss: 18.3425 - val_mae: 2.7574 - val_acc: 0.9892\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 13.1666 - mae: 2.6760 - acc: 0.9894 - val_loss: 18.0518 - val_mae: 2.7120 - val_acc: 0.9896\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 4s 488us/step - loss: 13.0856 - mae: 2.6684 - acc: 0.9896 - val_loss: 17.5462 - val_mae: 2.7229 - val_acc: 0.9900\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 4s 474us/step - loss: 13.0225 - mae: 2.6664 - acc: 0.9894 - val_loss: 18.9022 - val_mae: 2.8260 - val_acc: 0.9901\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 4s 476us/step - loss: 12.9287 - mae: 2.6610 - acc: 0.9896 - val_loss: 18.2973 - val_mae: 2.7478 - val_acc: 0.9897\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 4s 472us/step - loss: 13.0081 - mae: 2.6593 - acc: 0.9894 - val_loss: 17.8735 - val_mae: 2.7208 - val_acc: 0.9900\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.8386 - mae: 2.6521 - acc: 0.9894 - val_loss: 18.2353 - val_mae: 2.7580 - val_acc: 0.9895\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 12.8549 - mae: 2.6512 - acc: 0.9895 - val_loss: 18.2297 - val_mae: 2.7447 - val_acc: 0.9886\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 4s 483us/step - loss: 12.8283 - mae: 2.6496 - acc: 0.9896 - val_loss: 17.7394 - val_mae: 2.7300 - val_acc: 0.9903\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 4s 489us/step - loss: 12.7373 - mae: 2.6429 - acc: 0.9894 - val_loss: 17.5898 - val_mae: 2.7008 - val_acc: 0.9899\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 12.6343 - mae: 2.6389 - acc: 0.9895 - val_loss: 18.2361 - val_mae: 2.7206 - val_acc: 0.9901\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 4s 481us/step - loss: 12.6510 - mae: 2.6369 - acc: 0.9893 - val_loss: 17.3103 - val_mae: 2.7058 - val_acc: 0.9909\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 4s 480us/step - loss: 12.6237 - mae: 2.6335 - acc: 0.9896 - val_loss: 17.8403 - val_mae: 2.6937 - val_acc: 0.9886\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 4s 485us/step - loss: 12.5334 - mae: 2.6287 - acc: 0.9897 - val_loss: 17.6854 - val_mae: 2.7086 - val_acc: 0.9899\n",
      "2410/2410 [==============================] - 1s 243us/step\n",
      "4.229096834895738\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(hidden_units=64, activation='relu', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(hidden_units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(hidden_units, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(hidden_units=128, activation='sigmoid', optimizer='adam')\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OrderedDict([('max_depth', 81),\n",
    "             ('max_features', 'sqrt'),\n",
    "             ('min_samples_split', 5),\n",
    "             ('n_estimators', 86),\n",
    "             ('n_jobs', -1),\n",
    "             ('random_state', 2024)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5954839967045436\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=86, min_samples_split= 5, max_features='sqrt', max_depth= 81, random_state=rs, n_jobs=-1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_rfr=rfr.predict(X_test)\n",
    "distance=np.mean(np.sqrt(np.sum((y_rfr - y_test) ** 2, axis=1)))\n",
    "print(distance)\n",
    "\n",
    "eva_y=rfr.predict(eva_df)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('outputbayes1.csv', index=False, sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
