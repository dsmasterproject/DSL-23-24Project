{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "development = pd.read_csv(\"./../../DSL_Winter_Project_2024/development.csv\")\n",
    "\n",
    "outlier_column_index=[0, 7, 12, 15, 16, 17]\n",
    "columns_to_drop=[]\n",
    "\n",
    "for index in outlier_column_index:\n",
    "    columns_to_drop.append('pmax[%s]' % index)\n",
    "    columns_to_drop.append('negpmax[%s]' % index)\n",
    "    columns_to_drop.append('tmax[%s]' % index)\n",
    "    columns_to_drop.append('area[%s]' % index)\n",
    "    columns_to_drop.append('rms[%s]' % index)\n",
    "\n",
    "evaluation = pd.read_csv(\"./../../DSL_Winter_Project_2024/evaluation.csv\")\n",
    "eva=evaluation.drop(columns=columns_to_drop)\n",
    "eva_df=eva.drop(columns=[\"Id\"])\n",
    "\n",
    "df=development.drop(columns=columns_to_drop)\n",
    "X=df.drop(columns=['x', 'y'])\n",
    "y=df.loc[:,['x', 'y']]\n",
    "\n",
    "rs=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=5, step=1)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=32, max_value=512, step=32),\n",
    "                               activation='sigmoid'))\n",
    "        model.add(layers.Dropout(rate=hp.Float('dropout_' + str(i), min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(layers.Dense(units=2))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "                  loss='mse',\n",
    "                  metrics=['mae', 'acc'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory='my_tuning_directory',\n",
    "    project_name='my_first_tuning_project'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22 Complete [00h 13m 39s]\n",
      "val_loss: 33.81149164835612\n",
      "\n",
      "Best val_loss So Far: 25.951648076375324\n",
      "Total elapsed time: 13h 36m 54s\n",
      "\n",
      "Search: Running Trial #23\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |4                 |num_layers\n",
      "384               |480               |units_0\n",
      "0.4               |0.3               |dropout_0\n",
      "0.00019167        |0.00018093        |learning_rate\n",
      "480               |96                |units_1\n",
      "0.3               |0                 |dropout_1\n",
      "96                |160               |units_2\n",
      "0.1               |0.1               |dropout_2\n",
      "192               |96                |units_3\n",
      "0.1               |0.1               |dropout_3\n",
      "64                |256               |units_4\n",
      "0.3               |0.4               |dropout_4\n",
      "\n",
      "Epoch 1/50\n",
      "9638/9638 [==============================] - 6s 578us/step - loss: 61189.4531 - mae: 205.5058 - acc: 0.5173 - val_loss: 12498.0029 - val_mae: 94.9019 - val_acc: 0.5841\n",
      "Epoch 2/50\n",
      "9638/9638 [==============================] - 5s 569us/step - loss: 8088.4419 - mae: 74.4416 - acc: 0.9314 - val_loss: 4032.1946 - val_mae: 50.3624 - val_acc: 0.9826\n",
      "Epoch 3/50\n",
      "9638/9638 [==============================] - 6s 577us/step - loss: 2548.7080 - mae: 38.7589 - acc: 0.9616 - val_loss: 752.5608 - val_mae: 18.1161 - val_acc: 0.9852\n",
      "Epoch 4/50\n",
      "9638/9638 [==============================] - 5s 567us/step - loss: 991.2672 - mae: 24.2292 - acc: 0.9537 - val_loss: 184.8312 - val_mae: 8.7495 - val_acc: 0.9828\n",
      "Epoch 5/50\n",
      "9638/9638 [==============================] - 5s 567us/step - loss: 764.6944 - mae: 21.4638 - acc: 0.9531 - val_loss: 104.3314 - val_mae: 6.6328 - val_acc: 0.9832\n",
      "Epoch 6/50\n",
      "9638/9638 [==============================] - 5s 570us/step - loss: 717.7277 - mae: 20.7940 - acc: 0.9541 - val_loss: 83.3184 - val_mae: 6.1053 - val_acc: 0.9802\n",
      "Epoch 7/50\n",
      "9638/9638 [==============================] - 6s 593us/step - loss: 690.1576 - mae: 20.3747 - acc: 0.9557 - val_loss: 74.3301 - val_mae: 5.7225 - val_acc: 0.9818\n",
      "Epoch 8/50\n",
      "9638/9638 [==============================] - 6s 593us/step - loss: 674.2143 - mae: 20.1332 - acc: 0.9574 - val_loss: 67.4493 - val_mae: 5.4053 - val_acc: 0.9822\n",
      "Epoch 9/50\n",
      "9638/9638 [==============================] - 6s 586us/step - loss: 660.9006 - mae: 19.9339 - acc: 0.9579 - val_loss: 66.4260 - val_mae: 5.4158 - val_acc: 0.9820\n",
      "Epoch 10/50\n",
      "9638/9638 [==============================] - 6s 575us/step - loss: 649.0895 - mae: 19.7666 - acc: 0.9583 - val_loss: 62.8537 - val_mae: 5.2707 - val_acc: 0.9836\n",
      "Epoch 11/50\n",
      "9638/9638 [==============================] - 6s 572us/step - loss: 636.9801 - mae: 19.5749 - acc: 0.9593 - val_loss: 61.1358 - val_mae: 5.2014 - val_acc: 0.9842\n",
      "Epoch 12/50\n",
      "9638/9638 [==============================] - 6s 576us/step - loss: 626.5999 - mae: 19.3907 - acc: 0.9604 - val_loss: 57.0661 - val_mae: 4.9491 - val_acc: 0.9844\n",
      "Epoch 13/50\n",
      "9638/9638 [==============================] - 6s 587us/step - loss: 619.2147 - mae: 19.2839 - acc: 0.9602 - val_loss: 60.3385 - val_mae: 5.2171 - val_acc: 0.9850\n",
      "Epoch 14/50\n",
      "9638/9638 [==============================] - 6s 585us/step - loss: 611.9331 - mae: 19.1755 - acc: 0.9613 - val_loss: 54.4713 - val_mae: 4.8648 - val_acc: 0.9853\n",
      "Epoch 15/50\n",
      "9638/9638 [==============================] - 6s 586us/step - loss: 603.6473 - mae: 19.0486 - acc: 0.9608 - val_loss: 53.9591 - val_mae: 4.8770 - val_acc: 0.9857\n",
      "Epoch 16/50\n",
      "9638/9638 [==============================] - 6s 587us/step - loss: 598.3725 - mae: 18.9469 - acc: 0.9620 - val_loss: 57.2472 - val_mae: 5.1130 - val_acc: 0.9842\n",
      "Epoch 17/50\n",
      "9638/9638 [==============================] - 6s 581us/step - loss: 593.4525 - mae: 18.8780 - acc: 0.9628 - val_loss: 58.1273 - val_mae: 5.1797 - val_acc: 0.9840\n",
      "Epoch 18/50\n",
      "9638/9638 [==============================] - 5s 569us/step - loss: 588.2714 - mae: 18.7968 - acc: 0.9630 - val_loss: 50.4724 - val_mae: 4.6671 - val_acc: 0.9810\n",
      "Epoch 19/50\n",
      "9638/9638 [==============================] - 6s 575us/step - loss: 587.4998 - mae: 18.7801 - acc: 0.9633 - val_loss: 52.8919 - val_mae: 4.8798 - val_acc: 0.9844\n",
      "Epoch 20/50\n",
      "9638/9638 [==============================] - 5s 570us/step - loss: 580.8984 - mae: 18.6613 - acc: 0.9632 - val_loss: 50.4114 - val_mae: 4.7152 - val_acc: 0.9830\n",
      "Epoch 21/50\n",
      "9638/9638 [==============================] - 5s 567us/step - loss: 578.6650 - mae: 18.6369 - acc: 0.9635 - val_loss: 51.8144 - val_mae: 4.8494 - val_acc: 0.9844\n",
      "Epoch 22/50\n",
      "9638/9638 [==============================] - 5s 569us/step - loss: 573.5431 - mae: 18.5403 - acc: 0.9637 - val_loss: 49.9706 - val_mae: 4.6972 - val_acc: 0.9821\n",
      "Epoch 23/50\n",
      "9638/9638 [==============================] - 5s 569us/step - loss: 569.8680 - mae: 18.5000 - acc: 0.9634 - val_loss: 49.1706 - val_mae: 4.6776 - val_acc: 0.9852\n",
      "Epoch 24/50\n",
      "9638/9638 [==============================] - 5s 565us/step - loss: 568.7261 - mae: 18.4830 - acc: 0.9638 - val_loss: 53.0798 - val_mae: 4.9232 - val_acc: 0.9829\n",
      "Epoch 25/50\n",
      "9638/9638 [==============================] - 6s 572us/step - loss: 567.6072 - mae: 18.4580 - acc: 0.9637 - val_loss: 50.1242 - val_mae: 4.7411 - val_acc: 0.9834\n",
      "Epoch 26/50\n",
      "9638/9638 [==============================] - 5s 569us/step - loss: 566.6176 - mae: 18.4352 - acc: 0.9636 - val_loss: 51.3691 - val_mae: 4.8522 - val_acc: 0.9850\n",
      "Epoch 27/50\n",
      "9638/9638 [==============================] - 6s 572us/step - loss: 561.8425 - mae: 18.3695 - acc: 0.9637 - val_loss: 54.0357 - val_mae: 5.0160 - val_acc: 0.9842\n",
      "Epoch 28/50\n",
      "9638/9638 [==============================] - 6s 583us/step - loss: 561.8582 - mae: 18.3444 - acc: 0.9639 - val_loss: 51.9595 - val_mae: 4.8470 - val_acc: 0.9834\n",
      "Epoch 29/50\n",
      "9638/9638 [==============================] - 6s 585us/step - loss: 556.3732 - mae: 18.2579 - acc: 0.9645 - val_loss: 53.5192 - val_mae: 5.0295 - val_acc: 0.9851\n",
      "Epoch 30/50\n",
      "9638/9638 [==============================] - 6s 574us/step - loss: 557.3759 - mae: 18.2610 - acc: 0.9638 - val_loss: 49.4818 - val_mae: 4.7249 - val_acc: 0.9854\n",
      "Epoch 31/50\n",
      "9638/9638 [==============================] - 5s 569us/step - loss: 556.2869 - mae: 18.2627 - acc: 0.9639 - val_loss: 48.7042 - val_mae: 4.7090 - val_acc: 0.9845\n",
      "Epoch 32/50\n",
      "9638/9638 [==============================] - 6s 573us/step - loss: 553.1873 - mae: 18.1988 - acc: 0.9645 - val_loss: 50.4711 - val_mae: 4.8387 - val_acc: 0.9839\n",
      "Epoch 33/50\n",
      "9638/9638 [==============================] - 6s 582us/step - loss: 552.4858 - mae: 18.1937 - acc: 0.9641 - val_loss: 50.0008 - val_mae: 4.7984 - val_acc: 0.9830\n",
      "Epoch 34/50\n",
      "9638/9638 [==============================] - 6s 586us/step - loss: 549.6129 - mae: 18.1423 - acc: 0.9644 - val_loss: 49.0423 - val_mae: 4.7310 - val_acc: 0.9848\n",
      "Epoch 35/50\n",
      "9638/9638 [==============================] - 6s 583us/step - loss: 550.6418 - mae: 18.1543 - acc: 0.9638 - val_loss: 47.6181 - val_mae: 4.6172 - val_acc: 0.9854\n",
      "Epoch 36/50\n",
      "7336/9638 [=====================>........] - ETA: 1s - loss: 551.4970 - mae: 18.1561 - acc: 0.9642"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, tracing_options\u001b[38;5;241m=\u001b[39mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39mlookup(\n\u001b[1;32m    240\u001b[0m       lookup_func_type, current_func_context\n\u001b[1;32m    241\u001b[0m   )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_cache.py:50\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict[context]\u001b[38;5;241m.\u001b[39mdispatch(function_type)\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:456\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mitems()), \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaptures\u001b[38;5;241m.\u001b[39mitems())))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:895\u001b[0m, in \u001b[0;36mDenseSpec.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 895\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor_shape.py:1508\u001b[0m, in \u001b[0;36mTensorShape.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1506\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39m_dims\n\u001b[0;32m-> 1508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1509\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims)\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__reduce__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 3,\n",
       " 'units_0': 64,\n",
       " 'dropout_0': 0.1,\n",
       " 'learning_rate': 0.00012162727501515752,\n",
       " 'units_1': 32,\n",
       " 'dropout_1': 0.0,\n",
       " 'units_2': 448,\n",
       " 'dropout_2': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7710/7710 [==============================] - 7s 892us/step - loss: 116855.5000 - mae: 317.6105 - acc: 0.5209 - val_loss: 68227.0859 - val_mae: 233.4563 - val_acc: 0.5218\n",
      "Epoch 2/50\n",
      "7710/7710 [==============================] - 7s 856us/step - loss: 37385.9648 - mae: 159.8214 - acc: 0.4982 - val_loss: 17377.2930 - val_mae: 110.5212 - val_acc: 0.5218\n",
      "Epoch 3/50\n",
      "7710/7710 [==============================] - 7s 858us/step - loss: 12354.1582 - mae: 92.6348 - acc: 0.6011 - val_loss: 6243.1479 - val_mae: 63.1730 - val_acc: 0.9757\n",
      "Epoch 4/50\n",
      "7710/7710 [==============================] - 7s 862us/step - loss: 3544.8650 - mae: 42.8766 - acc: 0.9842 - val_loss: 1538.3059 - val_mae: 25.3227 - val_acc: 0.9843\n",
      "Epoch 5/50\n",
      "7710/7710 [==============================] - 7s 894us/step - loss: 660.7171 - mae: 14.4470 - acc: 0.9845 - val_loss: 191.6237 - val_mae: 7.5354 - val_acc: 0.9849\n",
      "Epoch 6/50\n",
      "7710/7710 [==============================] - 7s 895us/step - loss: 83.6166 - mae: 5.3404 - acc: 0.9855 - val_loss: 46.6792 - val_mae: 4.3630 - val_acc: 0.9856\n",
      "Epoch 7/50\n",
      "7710/7710 [==============================] - 7s 885us/step - loss: 31.2243 - mae: 3.8467 - acc: 0.9864 - val_loss: 31.4530 - val_mae: 3.4928 - val_acc: 0.9872\n",
      "Epoch 8/50\n",
      "7710/7710 [==============================] - 7s 923us/step - loss: 25.1839 - mae: 3.5459 - acc: 0.9871 - val_loss: 31.2078 - val_mae: 3.7432 - val_acc: 0.9866\n",
      "Epoch 9/50\n",
      "7710/7710 [==============================] - 7s 890us/step - loss: 22.6187 - mae: 3.3902 - acc: 0.9874 - val_loss: 26.8935 - val_mae: 3.2231 - val_acc: 0.9888\n",
      "Epoch 10/50\n",
      "7710/7710 [==============================] - 7s 858us/step - loss: 21.3573 - mae: 3.3122 - acc: 0.9875 - val_loss: 25.6503 - val_mae: 3.2303 - val_acc: 0.9884\n",
      "Epoch 11/50\n",
      "7710/7710 [==============================] - 7s 870us/step - loss: 20.2210 - mae: 3.2493 - acc: 0.9879 - val_loss: 24.8101 - val_mae: 3.2721 - val_acc: 0.9877\n",
      "Epoch 12/50\n",
      "7710/7710 [==============================] - 7s 881us/step - loss: 19.0804 - mae: 3.1901 - acc: 0.9882 - val_loss: 23.4902 - val_mae: 3.2281 - val_acc: 0.9878\n",
      "Epoch 13/50\n",
      "7710/7710 [==============================] - 7s 882us/step - loss: 18.4808 - mae: 3.1479 - acc: 0.9882 - val_loss: 22.8137 - val_mae: 3.1912 - val_acc: 0.9886\n",
      "Epoch 14/50\n",
      "7710/7710 [==============================] - 7s 854us/step - loss: 17.7679 - mae: 3.1101 - acc: 0.9883 - val_loss: 22.0306 - val_mae: 3.1302 - val_acc: 0.9887\n",
      "Epoch 15/50\n",
      "7710/7710 [==============================] - 8s 981us/step - loss: 17.3003 - mae: 3.0768 - acc: 0.9883 - val_loss: 21.7224 - val_mae: 3.1125 - val_acc: 0.9902\n",
      "Epoch 16/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 16.7928 - mae: 3.0409 - acc: 0.9884 - val_loss: 21.4460 - val_mae: 3.0486 - val_acc: 0.9883\n",
      "Epoch 17/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 16.5707 - mae: 3.0193 - acc: 0.9883 - val_loss: 22.0468 - val_mae: 3.0823 - val_acc: 0.9893\n",
      "Epoch 18/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 16.0107 - mae: 2.9849 - acc: 0.9885 - val_loss: 20.7586 - val_mae: 3.0566 - val_acc: 0.9879\n",
      "Epoch 19/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 15.7401 - mae: 2.9638 - acc: 0.9886 - val_loss: 22.9157 - val_mae: 3.0426 - val_acc: 0.9883\n",
      "Epoch 20/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 15.6256 - mae: 2.9500 - acc: 0.9885 - val_loss: 20.5166 - val_mae: 2.9869 - val_acc: 0.9885\n",
      "Epoch 21/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 15.3396 - mae: 2.9221 - acc: 0.9889 - val_loss: 21.5858 - val_mae: 3.0947 - val_acc: 0.9908\n",
      "Epoch 22/50\n",
      "7710/7710 [==============================] - 8s 999us/step - loss: 15.2342 - mae: 2.9105 - acc: 0.9886 - val_loss: 21.7039 - val_mae: 3.0552 - val_acc: 0.9878\n",
      "Epoch 23/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 14.9220 - mae: 2.8899 - acc: 0.9887 - val_loss: 21.5407 - val_mae: 2.9802 - val_acc: 0.9870\n",
      "Epoch 24/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 14.7806 - mae: 2.8789 - acc: 0.9889 - val_loss: 20.0599 - val_mae: 2.9417 - val_acc: 0.9880\n",
      "Epoch 25/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 14.5962 - mae: 2.8628 - acc: 0.9886 - val_loss: 19.9810 - val_mae: 2.9510 - val_acc: 0.9895\n",
      "Epoch 26/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 14.7246 - mae: 2.8426 - acc: 0.9886 - val_loss: 19.8350 - val_mae: 2.8816 - val_acc: 0.9908\n",
      "Epoch 27/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 14.4762 - mae: 2.8352 - acc: 0.9886 - val_loss: 21.0888 - val_mae: 2.9479 - val_acc: 0.9905\n",
      "Epoch 28/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 14.1072 - mae: 2.8181 - acc: 0.9888 - val_loss: 20.3802 - val_mae: 2.9967 - val_acc: 0.9898\n",
      "Epoch 29/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 14.1886 - mae: 2.8167 - acc: 0.9890 - val_loss: 20.0143 - val_mae: 2.9208 - val_acc: 0.9907\n",
      "Epoch 30/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.9076 - mae: 2.8014 - acc: 0.9890 - val_loss: 21.1528 - val_mae: 2.9057 - val_acc: 0.9910\n",
      "Epoch 31/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.8511 - mae: 2.7891 - acc: 0.9888 - val_loss: 19.3438 - val_mae: 2.8292 - val_acc: 0.9888\n",
      "Epoch 32/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.7724 - mae: 2.7790 - acc: 0.9890 - val_loss: 19.2953 - val_mae: 2.8388 - val_acc: 0.9897\n",
      "Epoch 33/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.6253 - mae: 2.7664 - acc: 0.9890 - val_loss: 20.5904 - val_mae: 2.9217 - val_acc: 0.9900\n",
      "Epoch 34/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.4381 - mae: 2.7563 - acc: 0.9891 - val_loss: 19.5242 - val_mae: 2.8673 - val_acc: 0.9895\n",
      "Epoch 35/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.3226 - mae: 2.7421 - acc: 0.9891 - val_loss: 19.6410 - val_mae: 2.9156 - val_acc: 0.9889\n",
      "Epoch 36/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.2503 - mae: 2.7395 - acc: 0.9892 - val_loss: 19.3535 - val_mae: 2.8029 - val_acc: 0.9915\n",
      "Epoch 37/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.0950 - mae: 2.7246 - acc: 0.9892 - val_loss: 19.8177 - val_mae: 2.8550 - val_acc: 0.9893\n",
      "Epoch 38/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 13.1031 - mae: 2.7198 - acc: 0.9891 - val_loss: 18.2004 - val_mae: 2.7815 - val_acc: 0.9904\n",
      "Epoch 39/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 12.8793 - mae: 2.7107 - acc: 0.9891 - val_loss: 19.9297 - val_mae: 2.8340 - val_acc: 0.9898\n",
      "Epoch 40/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 12.8169 - mae: 2.7009 - acc: 0.9892 - val_loss: 19.8478 - val_mae: 2.8532 - val_acc: 0.9895\n",
      "Epoch 41/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 12.7088 - mae: 2.6949 - acc: 0.9895 - val_loss: 20.3020 - val_mae: 2.7650 - val_acc: 0.9904\n",
      "Epoch 42/50\n",
      "7710/7710 [==============================] - 8s 1ms/step - loss: 12.6984 - mae: 2.6863 - acc: 0.9893 - val_loss: 21.4808 - val_mae: 2.8471 - val_acc: 0.9902\n",
      "Epoch 43/50\n",
      "7710/7710 [==============================] - 7s 905us/step - loss: 12.5064 - mae: 2.6754 - acc: 0.9894 - val_loss: 19.4539 - val_mae: 2.8043 - val_acc: 0.9891\n",
      "Epoch 44/50\n",
      "7710/7710 [==============================] - 7s 845us/step - loss: 12.4072 - mae: 2.6676 - acc: 0.9891 - val_loss: 19.8000 - val_mae: 2.8084 - val_acc: 0.9894\n",
      "Epoch 45/50\n",
      "7710/7710 [==============================] - 7s 867us/step - loss: 12.5084 - mae: 2.6607 - acc: 0.9894 - val_loss: 21.5409 - val_mae: 2.7926 - val_acc: 0.9899\n",
      "Epoch 46/50\n",
      "7710/7710 [==============================] - 7s 884us/step - loss: 12.3568 - mae: 2.6584 - acc: 0.9895 - val_loss: 20.2297 - val_mae: 2.8492 - val_acc: 0.9889\n",
      "Epoch 47/50\n",
      "7710/7710 [==============================] - 7s 875us/step - loss: 12.3901 - mae: 2.6557 - acc: 0.9894 - val_loss: 20.4533 - val_mae: 2.8155 - val_acc: 0.9896\n",
      "Epoch 48/50\n",
      "7710/7710 [==============================] - 7s 860us/step - loss: 12.2502 - mae: 2.6445 - acc: 0.9894 - val_loss: 20.1028 - val_mae: 2.8299 - val_acc: 0.9901\n",
      "Epoch 49/50\n",
      "7710/7710 [==============================] - 7s 874us/step - loss: 12.1595 - mae: 2.6346 - acc: 0.9897 - val_loss: 17.8096 - val_mae: 2.7826 - val_acc: 0.9894\n",
      "Epoch 50/50\n",
      "7710/7710 [==============================] - 7s 871us/step - loss: 12.2622 - mae: 2.6345 - acc: 0.9897 - val_loss: 22.0888 - val_mae: 2.8556 - val_acc: 0.9895\n",
      "2410/2410 [==============================] - 1s 366us/step\n",
      "4.462066137530622\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(activation='sigmoid', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],)),\n",
    "        layers.Dense(512, activation=activation),\n",
    "        layers.Dense(128, activation=activation),\n",
    "        layers.Dense(64, activation=activation),\n",
    "        layers.Dense(32, activation=activation),\n",
    "        layers.Dense(2)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_df_scaled = scaler.transform(eva_df)\n",
    "\n",
    "eva_y=model.predict(eva_df_scaled)\n",
    "\n",
    "df = pd.DataFrame(eva_y, columns=['Id', 'Predicted'])\n",
    "df['Predicted'] = df.apply(lambda row: f\"{row['Id']:.1f}|{row['Predicted']:.1f}\", axis=1)\n",
    "df['Id'] = df.index\n",
    "df.to_csv('tensor_output4.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import schedules\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def build_model(activation='sigmoid', optimizer='adam'):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=activation, input_dim=X_train.shape[1]),\n",
    "        #layers.Dropout(0.2),\n",
    "        layers.Dense(512, activation=activation),\n",
    "        #layers.Dropout(0.2),\n",
    "        layers.Dense(2, activation=None)\n",
    "    ])\n",
    "    \n",
    "    learning_rate_schedule = schedules.ExponentialDecay(initial_learning_rate=0.001, decay_steps=10000, decay_rate=0.9)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[\"mae\", \"acc\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "distance=np.mean(np.sqrt(np.sum((y_pred - y_test) ** 2, axis=1)))\n",
    "print(distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
